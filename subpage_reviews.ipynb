{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve and store in a list of url_ending. For example: [egcu.org,libertyfirstcu.com, etc]\n",
    "#loop through this list to have a consolidated \"soup\" and get 2 separated files: details & reviews of all companies\n",
    "#connect to Postgre using Psycopg and store as tables there\n",
    "#set up cron job & automated scraping for new reviews daily, then append them to the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "atm_url = 'https://www.trustpilot.com/categories/atm'\n",
    "\n",
    "BASE_URL = \"https://www.trustpilot.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for html parser\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    return BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_soup(atm_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scrap all the URLs of business page\n",
    "\n",
    "def get_company_urls(soup_response):\n",
    "    company_urls = []\n",
    "    for a in soup.select(\"a[name='business-unit-card']\"):\n",
    "        url_subdirectory = a.attrs.get(\"href\")\n",
    "        company_urls.append(BASE_URL+url_subdirectory)\n",
    "    return company_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the link of the next page button and scrap content on next page\n",
    "def get_next_page_url(soup_response):\n",
    "    return soup.select(\"a[name='pagination-button-next']\")[0].attrs.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap the list of company URLs\n",
    "company_urls = []\n",
    "\n",
    "while soup:\n",
    "    company_urls.extend(get_company_urls(soup))\n",
    "    next_page = get_next_page_url(soup)\n",
    "    if next_page:\n",
    "        soup = get_soup(BASE_URL+next_page)\n",
    "    else:\n",
    "        soup = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.trustpilot.com/review/acmeatm.cash',\n",
       " 'https://www.trustpilot.com/review/asicminersrig.com',\n",
       " 'https://www.trustpilot.com/review/asicminertech.com',\n",
       " 'https://www.trustpilot.com/review/cashexpressllc.com',\n",
       " 'https://www.trustpilot.com/review/coinhubatm.com',\n",
       " 'https://www.trustpilot.com/review/covaultbtm.com',\n",
       " 'https://www.trustpilot.com/review/cryptobaseatm.com',\n",
       " 'https://www.trustpilot.com/review/cryptodispensers.com',\n",
       " 'https://www.trustpilot.com/review/egcu.org',\n",
       " 'https://www.trustpilot.com/review/heritagevalleyfcu.org',\n",
       " 'https://www.trustpilot.com/review/koinkryptatm.com',\n",
       " 'https://www.trustpilot.com/review/kryptominerstech.com',\n",
       " 'https://www.trustpilot.com/review/libertyfirstcu.com',\n",
       " 'https://www.trustpilot.com/review/meriwest.com',\n",
       " 'https://www.trustpilot.com/review/northone.com',\n",
       " 'https://www.trustpilot.com/review/pnc.com',\n",
       " 'https://www.trustpilot.com/review/slide2thrive.com',\n",
       " 'https://www.trustpilot.com/review/swadesh.co',\n",
       " 'https://www.trustpilot.com/review/thepaymenthq.com',\n",
       " 'https://www.trustpilot.com/review/vtsymorwvyj7k29pndy4jsc60x6oud.burpcollaborator.net',\n",
       " 'https://www.trustpilot.com/review/wpc.services',\n",
       " 'https://www.trustpilot.com/review/www.coin.cloud'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove duplicates in the URL list if any\n",
    "\n",
    "deduplicated_company_urls = set(company_urls)\n",
    "deduplicated_company_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish connection with PostgreSQL using psycopg2\n",
    "\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "#Function to insert values into existing table\n",
    "def execute_values(conn, df, table):\n",
    "  \n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "  \n",
    "    col = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, col)\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"the dataframe is inserted\")\n",
    "    cursor.close()\n",
    "  \n",
    "  \n",
    "conn = psycopg2.connect(\n",
    "    database=\"atm_scraping\", user='postgres', password='postgres', host='127.0.0.1', port='5432'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n",
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for url in deduplicated_company_urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    data = []\n",
    "    name = soup.find('span', attrs={'class': 'typography_display-s__qOjh6 typography_appearance-default__AAY17 title_displayName__TtDDM'}).text.strip()\n",
    "    reviews = soup.find_all('div', attrs={'class': 'styles_cardWrapper__LcCPA styles_show__HUXRb styles_reviewCard__9HxJJ'})\n",
    "    for review in reviews:\n",
    "        review_stars = review.find_all('div', attrs={'class': 'star-rating_starRating__4rrcf star-rating_medium__iN6Ty'})\n",
    "        stars = [stars.find('img')['alt'].replace('Rated ', '').replace(' stars', '') for stars in review_stars]\n",
    "        review_dates = review.find('time', attrs={'class': '', 'data-service-review-date-time-ago': 'true'})\n",
    "        review_title = review.find('h2', attrs={'class': 'typography_heading-s__f7029 typography_appearance-default__AAY17'})\n",
    "        reviewer_name = review.find('span', attrs={'class': 'typography_heading-xxs__QKBS8 typography_appearance-default__AAY17'})\n",
    "        review_text = review.find('p', attrs={'class': 'typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn'})\n",
    "        experience_date = review.find('p', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-default__AAY17'})\n",
    "        review_reply_text = review.find('p', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-default__AAY17 styles_message__shHhX'})\n",
    "        reply_date_ = review.find('time', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_replyDate__Iem0_'})\n",
    "        star = stars[0] if stars else None\n",
    "        title = review_title.text.strip() if review_title else None\n",
    "        reviewer = reviewer_name.text.strip() if reviewer_name else None\n",
    "        text = review_text.text.strip() if review_text else None\n",
    "        experience = experience_date.text.split(':')[-1].strip() if experience_date else None\n",
    "        review_date = review_dates.get('datetime').split('T')[0].strip() if review_dates else None\n",
    "        reply_date = reply_date_.text.strip() if reply_date_ else None\n",
    "        reply_text = review_reply_text.text.strip() if review_reply_text else None\n",
    "        data.append([name, star, title, reviewer, text, experience, review_date, reply_date, reply_text])\n",
    "    columns = ['company_name','review_star', 'review_title', 'reviewer_name', 'review_text', 'experience_date', 'review_date', 'reply_date', 'reply_text']\n",
    "    df_reviews = pd.DataFrame(data, columns=columns)\n",
    "    execute_values(conn, df_reviews, 'reviews')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_star</th>\n",
       "      <th>review_title</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>experience_date</th>\n",
       "      <th>review_date</th>\n",
       "      <th>reply_date</th>\n",
       "      <th>review_reply_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>Payment HQ is the best Merchant…</td>\n",
       "      <td>Aqua Fix Water Store</td>\n",
       "      <td>Payment HQ is the best Merchant Services out t...</td>\n",
       "      <td>January 02, 2023</td>\n",
       "      <td>2023-07-07</td>\n",
       "      <td>Jul 8, 2023</td>\n",
       "      <td>Thank you for sharing your positive feedback! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>I am lucky to work with The Payment HQ!</td>\n",
       "      <td>Austin Kruck</td>\n",
       "      <td>I am lucky to have had an exceptional experien...</td>\n",
       "      <td>June 28, 2023</td>\n",
       "      <td>2023-06-29</td>\n",
       "      <td>Jun 30, 2023</td>\n",
       "      <td>Hi Austin, We appreciate you sharing your posi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_star                             review_title         reviewer_name  \\\n",
       "0  5 out of 5         Payment HQ is the best Merchant…  Aqua Fix Water Store   \n",
       "1  5 out of 5  I am lucky to work with The Payment HQ!          Austin Kruck   \n",
       "\n",
       "                                         review_text   experience_date  \\\n",
       "0  Payment HQ is the best Merchant Services out t...  January 02, 2023   \n",
       "1  I am lucky to have had an exceptional experien...     June 28, 2023   \n",
       "\n",
       "  review_date    reply_date                                  review_reply_text  \n",
       "0  2023-07-07   Jul 8, 2023  Thank you for sharing your positive feedback! ...  \n",
       "1  2023-06-29  Jun 30, 2023  Hi Austin, We appreciate you sharing your posi...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reviews\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "reviews = soup.find_all('div', attrs={'class': 'styles_cardWrapper__LcCPA styles_show__HUXRb styles_reviewCard__9HxJJ'})\n",
    "\n",
    "# Initialize lists to store the data\n",
    "data = []\n",
    "\n",
    "# Extract the data from each review container\n",
    "for review in reviews:\n",
    "    # Extract review stars\n",
    "    review_stars = review.find_all('div', attrs={'class': 'star-rating_starRating__4rrcf star-rating_medium__iN6Ty'})\n",
    "    stars = [stars.find('img')['alt'].replace('Rated ', '').replace(' stars', '') for stars in review_stars]\n",
    "\n",
    "    # Extract other review details\n",
    "    review_dates = review.find('time', attrs={'class': '', 'data-service-review-date-time-ago': 'true'})\n",
    "    review_title = review.find('h2', attrs={'class': 'typography_heading-s__f7029 typography_appearance-default__AAY17'})\n",
    "    reviewer_name = review.find('span', attrs={'class': 'typography_heading-xxs__QKBS8 typography_appearance-default__AAY17'})\n",
    "    review_text = review.find('p', attrs={'class': 'typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn'})\n",
    "    experience_date = review.find('p', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-default__AAY17'})\n",
    "    review_reply_text = review.find('p', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-default__AAY17 styles_message__shHhX'})\n",
    "    reply_date_ = review.find('time', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_replyDate__Iem0_'})\n",
    "\n",
    "    # Extract the values or set them as None if not found\n",
    "    star = stars[0] if stars else None\n",
    "    title = review_title.text.strip() if review_title else None\n",
    "    reviewer = reviewer_name.text.strip() if reviewer_name else None\n",
    "    text = review_text.text.strip() if review_text else None\n",
    "    experience = experience_date.text.split(':')[-1].strip() if experience_date else None\n",
    "    review_date = review_dates.get('datetime').split('T')[0].strip() if review_dates else None\n",
    "    reply_date = reply_date_.text.strip() if reply_date_ else None\n",
    "    reply_text = review_reply_text.text.strip() if review_reply_text else None\n",
    "\n",
    "    data.append([star, title, reviewer, text, experience, review_date, reply_date, reply_text])\n",
    "\n",
    "# Define column names for the DataFrame\n",
    "columns = ['review_star', 'review_title', 'reviewer_name', 'review_text', 'experience_date', 'review_date', 'reply_date', 'review_reply_text']\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df_reviews = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df_reviews.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jul 15, 2023'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = get_soup('https://www.trustpilot.com/review/libertyfirstcu.com')\n",
    "review_rating = reviews.find('time', attrs={'class': '', 'data-service-review-date-time-ago': 'true'}).text\n",
    "review_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scrap reviews: \n",
    "def parse_reviews(sub_soup):\n",
    "    data = []\n",
    "    reviews = sub_soup.find_all('div', attrs={'class': 'styles_reviewCardInner__EwDq2'})\n",
    "    for review in reviews: \n",
    "        rating = review.select(\"div[class='styles_reviewHeader__iU9Px']\")[0].attrs.get(\"data-service-review-rating\")\n",
    "        review_date = review.find('time', attrs={'class': '', 'data-service-review-date-time-ago': 'true'}).text\n",
    "        title = review.find('h2', attrs={'class': 'typography_heading-s__f7029 typography_appearance-default__AAY17'}).text\n",
    "        reviewer = review.find('span', attrs={'class': 'typography_heading-xxs__QKBS8 typography_appearance-default__AAY17'}).text\n",
    "        review_text = review.find('p', attrs={'class': 'typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn'})\n",
    "        experience_date = review.find('p', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-default__AAY17'})\n",
    "        reply_text = review.find('p', attrs={'class': 'typography_body-m__xgxZ_ typography_appearance-default__AAY17 styles_message__shHhX'})\n",
    "        reply_date = review.find('time', attrs={'class': '', 'data-service-review-business-reply-date-time-ago': 'true'})\n",
    "        experience = experience_date.text.split(':')[-1].strip() if experience_date else None\n",
    "    return data.append([rating, review_date, title, reviewer, review_text, experience, reply_text, reply_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'rating' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m company_page \u001b[39m=\u001b[39m get_soup(company_url)\n\u001b[1;32m      4\u001b[0m company_name \u001b[39m=\u001b[39m company_page\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mspan\u001b[39m\u001b[39m'\u001b[39m, attrs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mtypography_display-s__qOjh6 typography_appearance-default__AAY17 title_displayName__TtDDM\u001b[39m\u001b[39m'\u001b[39m})\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m----> 5\u001b[0m review_temp \u001b[39m=\u001b[39m parse_reviews(company_page)\n\u001b[1;32m      6\u001b[0m reviews_data\u001b[39m.\u001b[39mappend([company_name, review_temp])\n",
      "Cell \u001b[0;32mIn[83], line 15\u001b[0m, in \u001b[0;36mparse_reviews\u001b[0;34m(sub_soup)\u001b[0m\n\u001b[1;32m     13\u001b[0m     reply_date \u001b[39m=\u001b[39m review\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, attrs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdata-service-review-business-reply-date-time-ago\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m     14\u001b[0m     experience \u001b[39m=\u001b[39m experience_date\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip() \u001b[39mif\u001b[39;00m experience_date \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39mappend([rating, review_date, title, reviewer, review_text, experience, reply_text, reply_date])\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'rating' referenced before assignment"
     ]
    }
   ],
   "source": [
    "reviews_data = []\n",
    "for company_url in deduplicated_company_urls:\n",
    "    company_page = get_soup(company_url)\n",
    "    company_name = company_page.find('span', attrs={'class': 'typography_display-s__qOjh6 typography_appearance-default__AAY17 title_displayName__TtDDM'}).text.strip()\n",
    "    review_temp = parse_reviews(company_page)\n",
    "    reviews_data.append([company_name, review_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "9 columns passed, passed data had 1 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/construction.py:969\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    970\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    971\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/construction.py:1017\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_mi_list \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(columns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(content):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     \u001b[39m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m-> 1017\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m   1018\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(columns)\u001b[39m}\u001b[39;00m\u001b[39m columns passed, passed data had \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(content)\u001b[39m}\u001b[39;00m\u001b[39m columns\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1021\u001b[0m \u001b[39melif\u001b[39;00m is_mi_list:\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m     \u001b[39m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 9 columns passed, passed data had 1 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcompany_name\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mreview_star\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreview_title\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreviewer_name\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreview_text\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexperience_date\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreview_date\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreply_date\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreview_reply_text\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m df_reviews \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data\u001b[39m=\u001b[39;49mreviews_data, columns\u001b[39m=\u001b[39;49mcolumns)\n\u001b[1;32m      4\u001b[0m df_reviews\u001b[39m.\u001b[39mhead(\u001b[39m20\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:746\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 746\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    747\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    748\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    749\u001b[0m         data,\n\u001b[1;32m    750\u001b[0m         columns,\n\u001b[1;32m    751\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    752\u001b[0m         dtype,\n\u001b[1;32m    753\u001b[0m     )\n\u001b[1;32m    754\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    755\u001b[0m         arrays,\n\u001b[1;32m    756\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[0;32m--> 510\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    511\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    513\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/construction.py:875\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    872\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[1;32m    873\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 875\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    876\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/internals/construction.py:972\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    969\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    970\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    971\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 972\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contents) \u001b[39mand\u001b[39;00m contents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[1;32m    975\u001b[0m     contents \u001b[39m=\u001b[39m _convert_object_array(contents, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 9 columns passed, passed data had 1 columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = ['company_name','review_star', 'review_title', 'reviewer_name', 'review_text', 'experience_date', 'review_date', 'reply_date', 'review_reply_text']\n",
    "df_reviews = pd.DataFrame(data=reviews_data, columns=columns)\n",
    "\n",
    "df_reviews.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish connection with PostgreSQL using psycopg2\n",
    "\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "#Function to insert values into existing table\n",
    "def execute_values(conn, df, table):\n",
    "  \n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "  \n",
    "    col = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    query = \"DELETE FROM %s; INSERT INTO %s(%s) VALUES %%s\" % (table, table, col)\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"the dataframe is inserted\")\n",
    "    cursor.close()\n",
    "  \n",
    "  \n",
    "conn = psycopg2.connect(\n",
    "    database=\"atm_scraping\", user='postgres', password='postgres', host='127.0.0.1', port='5432'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "execute_values(conn, df_reviews, 'reviews')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
